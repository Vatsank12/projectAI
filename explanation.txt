================================================================================
                        VIGILANTAI PROJECT EXPLANATION
================================================================================

PROJECT OVERVIEW
================

VigilantAI is a comprehensive system monitoring and security dashboard designed to provide
real-time insights into computer system health, security threats, and performance metrics.
It combines traditional system monitoring with advanced AI-powered analysis to help users
maintain optimal system performance and security.

WHAT VIGILANTAI DOES
====================

1. SYSTEM MONITORING:
   - Real-time tracking of CPU, memory, disk, and network usage
   - System health scoring and performance analytics
   - Process monitoring with detailed resource consumption data
   - Temperature and uptime monitoring

2. SECURITY FEATURES:
   - File scanning with threat detection algorithms
   - SHA256 hash analysis for file verification
   - Quarantine system for suspicious files
   - Security alerts with severity levels (Critical, High, Medium, Low)

3. AI-POWERED ASSISTANT:
   - Intelligent chatbot using Groq's Llama-3.1-8B model
   - Automated system health analysis and recommendations
   - PC overheating detection and troubleshooting
   - Fallback to local AI when cloud services are unavailable

4. USER INTERFACE:
   - Modern cyberpunk-themed dashboard
   - Real-time charts and graphs using Chart.js
   - Responsive design for all screen sizes
   - Dark mode optimized for extended use

================================================================================
DETAILED IMPLEMENTATION
================================================================================

ARCHITECTURE OVERVIEW
=====================

The application follows a client-server architecture:

Frontend (Client):
- HTML5/CSS3/JavaScript application
- Served statically by FastAPI
- Real-time updates via polling and WebSockets

Backend (Server):
- FastAPI framework for REST API and WebSocket support
- Python-based system monitoring using psutil
- SQLite database for data persistence
- AI integration with Groq API

TECHNOLOGY STACK
================

BACKEND TECHNOLOGIES:
---------------------
- Python 3.12+: Core programming language
- FastAPI: Modern web framework for API development
- psutil: Cross-platform system monitoring library
- Groq AI: Cloud-based AI service for intelligent responses
- python-dotenv: Environment variable management
- uvicorn: ASGI server for FastAPI
- websockets: WebSocket protocol support
- python-multipart: File upload handling
- SQLite: Lightweight database for data persistence

FRONTEND TECHNOLOGIES:
----------------------
- HTML5: Semantic markup and structure
- Tailwind CSS: Utility-first CSS framework
- Vanilla JavaScript: Core functionality without frameworks
- Chart.js: Data visualization library
- Animate.css: CSS animation library
- Web APIs: Fetch API, WebSocket API, File API

CORE FEATURES IMPLEMENTATION
============================

1. REAL-TIME SYSTEM MONITORING
-------------------------------
Location: backend/routers/metrics.py

Implementation:
- Uses psutil.cpu_percent(), psutil.virtual_memory(), psutil.disk_usage()
- WebSocket connections for real-time updates (ConnectionManager class)
- Health scoring algorithm based on resource utilization
- Streaming metrics endpoint with asyncio background tasks

Key Functions:
- get_current_metrics(): Collects current system statistics
- stream_metrics(): Background task for continuous monitoring
- calculate_health_score(): AI-based health assessment

2. FILE SECURITY SCANNING
-------------------------
Location: backend/routers/scanner.py

Implementation:
- SHA256 hash calculation for file verification
- Threat scoring algorithm based on multiple indicators:
  * Suspicious file extensions (.exe, .bat, .scr, etc.)
  * File location in temp/cache directories
  * File size anomalies (>100MB or empty files)
  * MIME type analysis
  * File age analysis (recently modified files)
- Concurrent processing with ThreadPoolExecutor
- Batch processing for multiple files (4 files simultaneously)
- Progress tracking with abort functionality

Key Components:
- analyze_file(): Core threat detection logic
- batch_scan_files(): Concurrent file processing
- scan_directory_async(): Directory tree scanning
- Global scan_state dictionary for progress tracking

3. PROCESS MONITORING
---------------------
Location: backend/routers/processes.py

Implementation:
- psutil.process_iter() for process enumeration
- Resource consumption analysis (CPU, memory, disk I/O)
- Process details retrieval with error handling
- Process termination functionality (administrative privileges required)

Key Functions:
- get_top_processes(): Returns top 10 resource-intensive processes
- get_process_details(): Detailed process information
- kill_process(): Safe process termination

4. SECURITY ALERTS SYSTEM
-------------------------
Location: backend/routers/alerts.py

Implementation:
- Alert generation based on configurable thresholds
- Severity levels: Critical, High, Medium, Low
- Alert persistence and management
- Real-time alert broadcasting via WebSockets

Key Features:
- Automatic threshold-based alert generation
- Alert history and status tracking
- Color-coded visual indicators

5. AI ASSISTANT SYSTEM
----------------------
Location: backend/routers/assistant.py

Implementation:
- Dual AI system: Groq cloud AI + Local keyword-based AI
- Groq integration using llama-3.1-8b-instant model
- Intelligent overheating analysis and system recommendations
- Conversation history persistence
- Fallback mechanism for reliability

Key Components:
- generate_ai_response_with_groq(): Cloud AI processing
- generate_local_ai_response(): Local AI fallback
- Smart keyword matching for common queries
- System context integration in AI prompts

6. USER INTERFACE & DASHBOARD
-----------------------------
Location: frontend/ directory

Implementation:
- Single-page application with multiple views
- Cyberpunk theme with neon colors and glassmorphism effects
- Real-time chart updates using Chart.js
- Drag-and-drop file upload interface
- Progress bars and loading animations

Key Files:
- index.html: Login page
- dashboard.html: Main application interface
- styles.css: Custom CSS with animations
- main.js: Core application logic
- charts.js: Chart.js integration
- assistant.js: AI assistant interface

================================================================================
DATABASE AND DATA PERSISTENCE
================================================================================

DATABASE STRUCTURE
==================

VigilantAI uses SQLite for lightweight data persistence. The database file is located at:
backend/vigilant_ai.db

TABLES:
-------

1. alerts (if implemented):
   - id: Primary key
   - severity: Alert level (Critical/High/Medium/Low)
   - message: Alert description
   - timestamp: Creation time
   - acknowledged: Boolean status

2. scan_history (if implemented):
   - id: Primary key
   - file_path: Scanned file location
   - hash: File SHA256 hash
   - threat_score: Calculated threat level
   - scan_time: Timestamp

CURRENT IMPLEMENTATION:
----------------------
Currently, the application uses in-memory data structures for most operations:
- scanned_files: List of analyzed files
- quarantine_files: List of quarantined files
- conversations: AI assistant chat history

Future enhancements could include full database persistence for:
- Alert history
- Scan results
- User preferences
- System metrics history

================================================================================
API ENDPOINTS AND FUNCTIONALITY
================================================================================

METRICS API (metrics.py)
========================
GET /api/metrics/current
- Returns current system metrics (CPU, memory, disk, network)
- Response: JSON with timestamp and resource usage data

WS /api/metrics/ws/{client_id}
- WebSocket endpoint for real-time metrics streaming
- Sends continuous updates every second
- Handles client connections/disconnections

SCANNER API (scanner.py)
========================
GET /api/scanner/files
- Returns list of all scanned files
- Response: Array of file analysis objects

POST /api/scanner/scan
- Scans a single uploaded file
- Request: Multipart file upload
- Response: File analysis result

POST /api/scanner/batch-scan
- Scans multiple files concurrently
- Request: Multiple file uploads
- Response: Array of analysis results
- Performance: Processes 4 files simultaneously

POST /api/scanner/scan-directory
- Initiates directory tree scanning
- Request: Directory path
- Response: Scan initiation confirmation
- Background: Asynchronous scanning with progress tracking

GET /api/scanner/progress
- Returns current scan progress
- Response: Progress percentage, current file, total files

POST /api/scanner/abort
- Aborts currently running scan
- Response: Abort confirmation

GET /api/scanner/quarantine
- Returns list of quarantined files
- Response: Array of quarantined file objects

POST /api/scanner/quarantine/{file_hash}
- Moves file to quarantine
- Response: Quarantine confirmation

DELETE /api/scanner/quarantine/{file_hash}
- Restores file from quarantine
- Response: Restore confirmation

PROCESSES API (processes.py)
============================
GET /api/processes/list
- Returns top processes by resource usage
- Response: Array of process objects with CPU/memory stats

GET /api/processes/details/{pid}
- Returns detailed information for specific process
- Response: Complete process information

POST /api/processes/kill/{pid}
- Terminates specified process
- Response: Termination confirmation
- Security: Requires administrative privileges

GET /api/processes/system-info
- Returns comprehensive system information
- Response: CPU cores, RAM, disk space, uptime

ALERTS API (alerts.py)
======================
GET /api/alerts/
- Returns all alerts
- Response: Array of alert objects

GET /api/alerts/unread
- Returns unread alerts only
- Response: Filtered alert array

POST /api/alerts/{id}/read
- Marks specific alert as read
- Response: Update confirmation

DELETE /api/alerts/{id}
- Deletes specific alert
- Response: Deletion confirmation

ASSISTANT API (assistant.py)
============================
POST /api/assistant/message
- Sends message to AI assistant
- Request: JSON with message text
- Response: AI response with conversation ID

GET /api/assistant/history
- Returns conversation history
- Response: Array of conversation objects

GET /api/assistant/health-insight
- Returns AI-generated health insights
- Response: Health analysis and recommendations

GET /api/assistant/quick-actions
- Returns available quick actions
- Response: Array of action objects

================================================================================
CODE ARCHITECTURE AND FLOW
================================================================================

APPLICATION STARTUP (main.py)
=============================

1. FastAPI application initialization
2. CORS middleware configuration
3. Router inclusion (metrics, scanner, processes, alerts, assistant)
4. Static file mounting for frontend
5. Server startup with uvicorn

FRONTEND ARCHITECTURE (main.js)
===============================

1. Page initialization and event binding
2. Real-time metrics updates (every 1 second)
3. Chart.js initialization for performance graphs
4. File upload handling with drag-and-drop
5. Process monitoring and management
6. AI assistant chat interface
7. Alert system with notifications

SCANNING WORKFLOW
=================

1. User selects files or directory
2. Frontend sends request to appropriate API endpoint
3. Backend processes files concurrently using ThreadPoolExecutor
4. Progress updates sent to frontend via polling
5. Results displayed with threat scoring
6. Suspicious files automatically quarantined

AI ASSISTANT WORKFLOW
====================

1. User sends message via chat interface
2. Frontend sends POST request to /api/assistant/message
3. Backend attempts Groq API call first
4. If Groq fails, falls back to local keyword matching
5. Response includes system context for intelligent answers
6. Conversation stored in memory for history

================================================================================
PERFORMANCE OPTIMIZATIONS
================================================================================

1. CONCURRENT PROCESSING:
   - File scanning uses ThreadPoolExecutor for CPU-intensive hash calculations
   - Batch processing of 4 files simultaneously
   - Async/await patterns for I/O operations

2. MEMORY MANAGEMENT:
   - Temporary files cleaned up immediately after scanning
   - In-memory data structures for current session
   - Efficient WebSocket connection management

3. UI OPTIMIZATIONS:
   - Debounced updates for real-time metrics
   - Lazy loading of chart data
   - Efficient DOM manipulation

4. ERROR HANDLING:
   - Graceful fallbacks for failed operations
   - Comprehensive exception handling
   - User-friendly error messages

================================================================================
SECURITY CONSIDERATIONS
================================================================================

1. FILE SCANNING SECURITY:
   - SHA256 hash verification
   - Safe file handling with temporary directories
   - No execution of suspicious files

2. API SECURITY:
   - CORS configuration for development
   - Input validation on all endpoints
   - Safe process termination (no arbitrary command execution)

3. AI SAFETY:
   - System context isolation in AI prompts
   - Fallback to safe local responses
   - No sensitive data exposure in AI responses

================================================================================
FUTURE ENHANCEMENTS
================================================================================

PLANNED FEATURES:
- User authentication and multi-user support
- Database persistence for all data
- Email notifications for alerts
- Custom alert rules and thresholds
- Performance analytics and reporting
- Mobile application
- Advanced threat detection with machine learning
- Network monitoring and firewall integration

TECHNICAL IMPROVEMENTS:
- Full database implementation
- Docker containerization
- Unit and integration testing
- CI/CD pipeline
- Performance monitoring and optimization
- Security audits and penetration testing

================================================================================
CONCLUSION
================================================================================

VigilantAI represents a comprehensive solution for system monitoring and security,
combining traditional monitoring tools with modern AI capabilities. The application
demonstrates best practices in full-stack development, real-time data processing,
and user experience design.

The modular architecture allows for easy extension and maintenance, while the
dual AI system ensures reliability and intelligent responses. The concurrent
processing optimizations ensure good performance even with large file sets.

This project serves as both a practical tool for system administrators and a
demonstration of modern web development techniques using FastAPI, real-time
updates, and AI integration.